{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import (Input, Activation, BatchNormalization, Flatten,\n",
    "                                     Conv2D, MaxPooling2D, Dense)\n",
    "from statistics import mode\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    X_input = Input((288, 432, 4))\n",
    "\n",
    "    X = Conv2D(8, kernel_size=(3, 3), strides=(1, 1))(X_input)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "\n",
    "    X = Conv2D(16, kernel_size=(3, 3), strides=(1, 1))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "\n",
    "    X = Conv2D(32, kernel_size=(3, 3), strides=(1, 1))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "\n",
    "    X = Conv2D(64, kernel_size=(3, 3), strides=(1, 1))(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "\n",
    "    X = Conv2D(128, kernel_size=(3, 3), strides=(1, 1))(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "\n",
    "    X = Conv2D(256, kernel_size=(3, 3), strides=(1, 1))(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    X = Dense(8, activation='softmax', name='fc' + str(8),\n",
    "              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=9))(X)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=X_input, outputs=X, name='GenreModel')\n",
    "\n",
    "    model.load_weights(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def convert_mp32wav(file_path):\n",
    "    sound = AudioSegment.from_file(file_path)\n",
    "    sound.set_frame_rate(22050)\n",
    "    sound.export(\"./reference_samples/ref_full.wav\", format='wav')\n",
    "\n",
    "\n",
    "def extract_mel(wav_file_path):\n",
    "    \"\"\"\n",
    "    Cut off the first 30 seconds of the song and calculate the mel-spectrums\n",
    "    The input file must be in wav format\n",
    "    \"\"\"\n",
    "    wav = AudioSegment.from_file(wav_file_path)\n",
    "    for i in range(0, 10):\n",
    "        wav3sec = wav[i * 3 * 1000: (i + 1) * 3 * 1000]\n",
    "        samples = wav3sec.get_array_of_samples()\n",
    "        arr = np.array(samples).astype(np.float32)\n",
    "        mels = librosa.feature.melspectrogram(y=arr, sr=22050, n_mels=128, fmax=8000)\n",
    "        mels = librosa.power_to_db(mels, ref=np.max)\n",
    "\n",
    "        fig = plt.Figure()\n",
    "        canvas = FigureCanvas(fig)\n",
    "        p = plt.imshow(mels)\n",
    "\n",
    "        plt.savefig(f\"./reference_samples/sample_melspec{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def predict(song_path, _model):\n",
    "    convert_mp32wav(song_path)\n",
    "    extract_mel(\"./reference_samples/ref_full.wav\")\n",
    "    labels = []\n",
    "    for i in range(0, 10):\n",
    "        image = load_img(f\"./reference_samples/sample_melspec{i}.png\",\n",
    "                         color_mode='rgba',\n",
    "                         target_size=(288, 432))\n",
    "\n",
    "        image = img_to_array(image)\n",
    "        image = np.reshape(image, (1, 288, 432, 4))\n",
    "\n",
    "        prediction = _model.predict(image / 255)\n",
    "        prediction = prediction.reshape((8,))\n",
    "\n",
    "        class_label = np.argmax(prediction)\n",
    "        labels.append(class_label)\n",
    "    return mode(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "genre_model = tf.keras.models.load_model(\"./model/model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "classes = [\"Electronic\",\n",
    "           \"Experimental\",\n",
    "           \"Folk\",\n",
    "           \"Hip-Hop\",\n",
    "           \"Instrumental\",\n",
    "           \"International\",\n",
    "           \"Pop\",\n",
    "           \"Rock\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental\n"
     ]
    }
   ],
   "source": [
    "## test the model performance\n",
    "_label = predict(\"../test_playlist/Paris In The Rain - Lauv.mp3\",\n",
    "                 genre_model)\n",
    "print(classes[_label])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "## give recommendations based on the playlist\n",
    "## first load the list of songs from FMA\n",
    "metafile_path = \"/home/minhhiu/MyProjects/music_data/fma_metadata\"\n",
    "\n",
    "# load meta data\n",
    "tracks = utils.load(os.path.join(metafile_path, 'tracks.csv'))\n",
    "\n",
    "tracks_small = tracks[tracks['set', 'subset'] <= 'small']\n",
    "tracks = tracks_small['track']\n",
    "artists = tracks_small['artist']\n",
    "# print(tracks_small)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "## number of songs that will be recommended\n",
    "recommendation_num = 10\n",
    "\n",
    "genre_distribution = {\"Electronic\": 0,\n",
    "                      \"Experimental\": 0,\n",
    "                      \"Folk\": 0,\n",
    "                      \"Hip-Hop\": 0,\n",
    "                      \"Instrumental\": 0,\n",
    "                      \"International\": 0,\n",
    "                      \"Pop\": 0,\n",
    "                      \"Rock\": 0}\n",
    "\n",
    "genre_count = {\"Electronic\": 0,\n",
    "               \"Experimental\": 0,\n",
    "               \"Folk\": 0,\n",
    "               \"Hip-Hop\": 0,\n",
    "               \"Instrumental\": 0,\n",
    "               \"International\": 0,\n",
    "               \"Pop\": 0,\n",
    "               \"Rock\": 0}\n",
    "\n",
    "playlist_path = \"../test_playlist/\"\n",
    "playlist = os.listdir(playlist_path)\n",
    "total_songs_in_playlist = len(os.listdir(playlist_path))\n",
    "\n",
    "## calculate genre distribution over the playlist\n",
    "for song in playlist:\n",
    "    genre = classes[\n",
    "        predict(os.path.join(playlist_path, song), genre_model)\n",
    "    ]\n",
    "    genre_count[genre] += 1\n",
    "    genre_distribution[genre] = genre_count[genre] / total_songs_in_playlist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Playlist:\n",
      "Enchanted - Taylor Swift\n",
      "Lo Xa - Tien Tien\n",
      "New Divide - Linkin Park\n",
      "I Like Me Better - Lauv\n",
      "Dancing With Your Ghost - Sasha Sloan\n",
      "Numb - Linkin Park\n",
      "Paris In The Rain - Lauv\n",
      "Say You Do - Tien Tien\n",
      "Disconnected - Pegboard Nerds\n",
      "You Belong With Me Taylor___s Version_ -\n",
      "\n",
      "Recommendations:\n",
      "After the War (ft. Alex, MoShang, HEJ31) - SackJo22\n",
      "Bahia - Prince Rama\n",
      "high fidelity - File Under Toner\n",
      "Week One - Ben von Wildenhaus\n",
      "Prairie Kids - Meaner Pencil\n",
      "Opotiki Over and Out - krackatoa\n",
      "Halloween Night - Monk Turner\n",
      "Thinking Of You - Teeel\n",
      "Be Electric - Rockit Maxx\n",
      "While you're waiting for the revolution - Action Will Be Taken\n"
     ]
    }
   ],
   "source": [
    "## my playlist\n",
    "print(\"My Playlist:\")\n",
    "for song in os.listdir(playlist_path):\n",
    "    print(song.strip('.mp3'))\n",
    "\n",
    "recommendation_list = []\n",
    "for key in genre_distribution.keys():\n",
    "    songs_num = genre_distribution[key] * recommendation_num\n",
    "    if songs_num == 0:\n",
    "        continue\n",
    "    _tracks = tracks[tracks['genre_top'] == key]\n",
    "\n",
    "    rows = np.random.choice(_tracks.index.values, int(songs_num))\n",
    "    recommend_tracks = _tracks.loc[rows, :]\n",
    "    correspond_artist = artists.loc[rows, :]\n",
    "\n",
    "    for idx in recommend_tracks.index.values:\n",
    "        obj = {\n",
    "            \"Title\": recommend_tracks.loc[idx, :]['title'],\n",
    "            \"Artist\": artists.loc[idx, :]['name']\n",
    "        }\n",
    "        recommendation_list.append(obj)\n",
    "\n",
    "print()\n",
    "print(\"Recommendations:\")\n",
    "for obj in recommendation_list:\n",
    "    print(f\"{obj['Title']} - {obj['Artist']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}